{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te, xs_tr, xs_te = load_adult_data(svm=False,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPsDataSet(TensorDataset):\n",
    "\n",
    "    def __init__(self, *dataarrays):\n",
    "        tensors = (torch.tensor(da).float() for da in dataarrays)\n",
    "        super(NPsDataSet, self).__init__(*tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = y_tr.astype('float32')\n",
    "y_te = y_te.astype('float32')\n",
    "train_data = NPsDataSet(X_tr, y_tr, xs_tr)\n",
    "test_data = NPsDataSet(X_te, y_te, xs_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training samples: 34189\n",
      "# batches: 1068\n"
     ]
    }
   ],
   "source": [
    "print('# training samples:', len(train_data))\n",
    "print('# batches:', len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, n_features, n_hidden=32, p_dropout=0.2):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p_dropout),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p_dropout),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p_dropout),\n",
    "            nn.Linear(n_hidden, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.sigmoid(self.network(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = train_data.tensors[0].shape[1]\n",
    "clf = Classifier(n_features=n_features)\n",
    "clf_criterion = nn.BCELoss()\n",
    "clf_optimizer = optim.Adam(clf.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srp/.pyenv/versions/pytorch15/lib/python3.8/site-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/srp/.pyenv/versions/pytorch15/lib/python3.8/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "N_CLF_EPOCHS = 2\n",
    "\n",
    "for epoch in range(N_CLF_EPOCHS):\n",
    "    for x, y, _ in train_loader:\n",
    "        clf.zero_grad()\n",
    "        p_y = clf(x)\n",
    "        loss = clf_criterion(p_y, y)\n",
    "        loss.backward()\n",
    "        clf_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adversary(nn.Module):\n",
    "\n",
    "    def __init__(self, n_sensitive, n_hidden=32):\n",
    "        super(Adversary, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(1, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_sensitive),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.sigmoid(self.network(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srp/.pyenv/versions/pytorch15/lib/python3.8/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "lambdas = torch.Tensor([200, 30])\n",
    "adv = Adversary(xs_tr.shape[1])\n",
    "adv_criterion = nn.BCELoss(reduce=False)\n",
    "adv_optimizer = optim.Adam(adv.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ADV_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adversary(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(N_ADV_EPOCHS):\n",
    "    for x, _, z in train_loader:\n",
    "        adv.zero_grad()\n",
    "        p_y = clf(x).detach()\n",
    "        p_z = adv(p_y)\n",
    "        loss = (adv_criterion(p_z, z) * lambdas).mean()\n",
    "        loss.backward()\n",
    "        adv_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCH_COMBINED = 165\n",
    "\n",
    "for epoch in range(1, N_EPOCH_COMBINED):\n",
    "\n",
    "    # Train adversary\n",
    "    for x, y, z in train_loader:\n",
    "        adv.zero_grad()\n",
    "        p_y = clf(x)\n",
    "        p_z = adv(p_y)\n",
    "        loss_adv = (adv_criterion(p_z, z) * lambdas).mean()\n",
    "        loss_adv.backward()\n",
    "        adv_optimizer.step()\n",
    "\n",
    "    # Train classifier on single batch\n",
    "    for x, y, z in train_loader:\n",
    "        pass  # Ugly way to get a single batch\n",
    "    clf.zero_grad()\n",
    "    p_y = clf(x)\n",
    "    p_z = adv(p_y)\n",
    "    loss_adv = (adv_criterion(p_z, z) * lambdas).mean()\n",
    "    clf_loss = clf_criterion(p_y, y) - (adv_criterion(adv(p_y), z) * lambdas).mean()\n",
    "    clf_loss.backward()\n",
    "    clf_optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing Fair NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'bce_loss' from 'fair_eval' (/home/srp/Fairness/fairness_audit/codes/fair_eval.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-9f0421747048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfair_eval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalculate_prule_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_odds_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_parity_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_group_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml2_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbce_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_overall_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'bce_loss' from 'fair_eval' (/home/srp/Fairness/fairness_audit/codes/fair_eval.py)"
     ]
    }
   ],
   "source": [
    "from fair_eval import calculate_prule_clf, calculate_odds_clf, calculate_parity_reg, calculate_group_loss,l2_loss, calculate_overall_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (clf(torch.tensor(X_te).float())>0.5).float()\n",
    "pred = pred.cpu().detach().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ = clf(torch.tensor(X_te).float())\n",
    "pred_ = pred_.cpu().detach().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disparate impact:  97.62592268977488\n",
      "disparate misclassification rate:  83.1986660114709\n",
      "disparate false positive rate: nan\n",
      "disparate false negative rate: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srp/Fairness/fairness_audit/codes/fair_eval.py:24: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  prule = min((fr0/s0)/(fr1/s1),(fr1/s1)/(fr0/s0))*100\n",
      "/home/srp/Fairness/fairness_audit/codes/fair_eval.py:24: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  prule = min((fr0/s0)/(fr1/s1),(fr1/s1)/(fr0/s0))*100\n"
     ]
    }
   ],
   "source": [
    "calculate_prule_clf(pred,y_te,xs_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equalized opportunity for 0.0 : 67.96607568463152\n",
      "equalized opportunity for 1.0 : 68.42355371900827\n"
     ]
    }
   ],
   "source": [
    "calculate_odds_clf(pred,y_te,xs_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss function:  bce_loss\n",
      "loss value for group 0: 0.34681829810142517\n",
      "loss value for group 1: 0.5016478896141052\n"
     ]
    }
   ],
   "source": [
    "calculate_group_loss(bce_loss,pred_,y_te,xs_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7950910297044299"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_overall_accuracy(pred,y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch15",
   "language": "python",
   "name": "pytorch15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
